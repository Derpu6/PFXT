# learning_feedback.py
import streamlit as st
import os
import json
import pandas as pd
import numpy as np
import altair as alt
from datetime import datetime
import re

# æ·»åŠ å…¨å±€ç›®å½•å®šä¹‰
REFLECTIONS_DIR = "student_reflections"
RESULTS_DIR = "exam_results"


def extract_emotion_score(analysis_text):
    """ä»Žåˆ†æžæ–‡æœ¬ä¸­æå–æƒ…ç»ªè¯„åˆ†"""
    emotion_pattern = r'æƒ…ç»ªçŠ¶æ€:\s*(\d+)/10'
    match = re.search(emotion_pattern, analysis_text)
    if match:
        return int(match.group(1))
    return 5  # é»˜è®¤å€¼


def extract_motivation_score(analysis_text):
    """ä»Žåˆ†æžæ–‡æœ¬ä¸­æå–åŠ¨æœºè¯„åˆ†"""
    motivation_pattern = r'å­¦ä¹ åŠ¨æœº:\s*(\d+)/10'
    match = re.search(motivation_pattern, analysis_text)
    if match:
        return int(match.group(1))
    return 5  # é»˜è®¤å€¼


def show_learning_feedback():
    """æ˜¾ç¤ºå­¦æƒ…åé¦ˆç•Œé¢"""
    st.header("ðŸ“Š å­¦æƒ…åé¦ˆ")

    if st.session_state.exam_config is None:
        st.warning("è¯·å…ˆåŠ è½½æˆ–åˆ›å»ºä¸€ä¸ªè¯„åˆ†é…ç½®ï¼")
        return

    exam_name = st.session_state.exam_config['exam_name']
    st.subheader(f"å½“å‰è¯„åˆ†: {exam_name}")

    st.subheader("ç­çº§æ•´ä½“è¡¨çŽ°")

    if not os.path.exists(RESULTS_DIR):
        st.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¯„åˆ†ç»“æžœæ•°æ®")
        return

    result_files = [f for f in os.listdir(RESULTS_DIR) if f.endswith(".json")]
    if not result_files:
        st.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¯„åˆ†ç»“æžœæ–‡ä»¶")
        return

    exam_results = []
    for file in result_files:
        if exam_name in file:
            filepath = os.path.join(RESULTS_DIR, file)
            with open(filepath, 'r', encoding='utf-8') as f:
                result = json.load(f)
                exam_results.append(result)

    if not exam_results:
        st.warning(f"æ²¡æœ‰æ‰¾åˆ°'{exam_name}'çš„è¯„åˆ†ç»“æžœ")
        return

    students = []
    scores = []
    for result in exam_results:
        students.append(f"{result['student_id']}_{result['student_name']}")
        scores.append(result['total_score'])

    avg_score = np.mean(scores) if scores else 0
    max_score = max(scores) if scores else 0
    min_score = min(scores) if scores else 0

    col1, col2, col3 = st.columns(3)
    col1.metric("å¹³å‡åˆ†", f"{avg_score:.1f}")
    col2.metric("æœ€é«˜åˆ†", max_score)
    col3.metric("æœ€ä½Žåˆ†", min_score)

    st.write("å­¦ç”Ÿæˆç»©åˆ†å¸ƒ:")
    chart_data = pd.DataFrame({'å­¦ç”Ÿ': students, 'åˆ†æ•°': scores})
    chart = alt.Chart(chart_data).mark_bar().encode(
        x=alt.X('å­¦ç”Ÿ', sort=None),
        y='åˆ†æ•°',
        color=alt.value('skyblue')
    ).properties(width=600, height=300)
    text = chart.mark_text(align='center', baseline='bottom', dy=-5).encode(text='åˆ†æ•°')
    st.altair_chart(chart + text)

    st.subheader("æˆç»©åˆ†å¸ƒåˆ†æž")
    st.write(f"- ä¼˜ç§€ (â‰¥90åˆ†): {len([s for s in scores if s >= 90])}äºº")
    st.write(f"- è‰¯å¥½ (80-89åˆ†): {len([s for s in scores if 80 <= s < 90])}äºº")
    st.write(f"- ä¸­ç­‰ (70-79åˆ†): {len([s for s in scores if 70 <= s < 80])}äºº")
    st.write(f"- åŠæ ¼ (60-69åˆ†): {len([s for s in scores if 60 <= s < 70])}äºº")
    st.write(f"- ä¸åŠæ ¼ (<60åˆ†): {len([s for s in scores if s < 60])}äºº")

    st.subheader("ç­çº§å¼ºé¡¹ä¸Žå¼±é¡¹åˆ†æž")
    topic_scores = {}
    topic_counts = {}
    question_map = {
        q["title"]: q["total"]
        for q in st.session_state.exam_config.get("questions", [])
    }

    for result in exam_results:
        for topic, score in result["scores"].items():
            if topic == "ä»£ç è´¨é‡":
                total = st.session_state.exam_config.get("code_total", 15)
            else:
                total = question_map.get(topic, 100)
            score_rate = (score / total) * 100 if total > 0 else 0

            if topic not in topic_scores:
                topic_scores[topic] = 0
                topic_counts[topic] = 0

            topic_scores[topic] += score_rate
            topic_counts[topic] += 1

    topics = []
    avg_topic_scores = []
    for topic, total_score in topic_scores.items():
        count = topic_counts[topic]
        avg_score = total_score / count
        topics.append(topic)
        avg_topic_scores.append(avg_score)

    strong_topics = []
    weak_topics = []
    for i, score in enumerate(avg_topic_scores):
        if score >= 85:
            strong_topics.append(topics[i])
        elif score < 70:
            weak_topics.append(topics[i])

    col1, col2 = st.columns(2)
    with col1:
        st.success("**ç­çº§å¼ºé¡¹**")
        if strong_topics:
            for topic in strong_topics:
                st.write(f"- {topic} (å¾—åˆ†çŽ‡: {avg_topic_scores[topics.index(topic)]:.1f}%)")
        else:
            st.write("æš‚æ— æ˜¾è‘—å¼ºé¡¹")
    with col2:
        st.warning("**ç­çº§å¼±é¡¹**")
        if weak_topics:
            for topic in weak_topics:
                st.write(f"- {topic} (å¾—åˆ†çŽ‡: {avg_topic_scores[topics.index(topic)]:.1f}%)")
        else:
            st.write("æš‚æ— æ˜¾è‘—å¼±é¡¹")

    st.subheader("å„é¢˜ç›®å¾—åˆ†çŽ‡")
    topic_df = pd.DataFrame({'é¢˜ç›®': topics, 'å¹³å‡å¾—åˆ†çŽ‡': avg_topic_scores})
    chart = alt.Chart(topic_df).mark_bar().encode(
        x=alt.X('é¢˜ç›®', sort=None, axis=alt.Axis(labelAngle=45)),
        y=alt.Y('å¹³å‡å¾—åˆ†çŽ‡', scale=alt.Scale(domain=[0, 100])),
        color=alt.Color('å¹³å‡å¾—åˆ†çŽ‡:Q',
                        scale=alt.Scale(domain=[0, 70, 85, 100],
                                        range=['red', 'skyblue', 'green', 'green']),
                        legend=None)
    ).properties(width=600, height=400)
    rule_85 = alt.Chart(pd.DataFrame({'y': [85]})).mark_rule(color='green', strokeDash=[5, 5]).encode(y='y')
    rule_70 = alt.Chart(pd.DataFrame({'y': [70]})).mark_rule(color='red', strokeDash=[5, 5]).encode(y='y')
    text = chart.mark_text(align='center', baseline='bottom', dy=-5).encode(text=alt.Text('å¹³å‡å¾—åˆ†çŽ‡:Q', format='.1f'))
    st.altair_chart(chart + rule_85 + rule_70 + text)

    st.subheader("ä¸ªäººåˆ†æ•°åˆ†æž")
    selected_student = st.selectbox("é€‰æ‹©å­¦ç”Ÿ", students)
    student_result = None
    for result in exam_results:
        if f"{result['student_id']}_{result['student_name']}" == selected_student:
            student_result = result
            break

    if not student_result:
        st.warning("æ‰¾ä¸åˆ°è¯¥å­¦ç”Ÿçš„è¯¦ç»†ç»“æžœ")
        return

    st.metric(f"{selected_student}çš„åˆ†æ•°", f"{student_result['total_score']}åˆ†")
    st.write("å…·ä½“è¡¨çŽ°:")
    col1, col2 = st.columns(2)
    with col1:
        st.info("**å¼ºé¡¹**")
        strong_topics = []
        for topic, score in student_result['scores'].items():
            for q in st.session_state.exam_config.get('questions', []):
                if q['title'] == topic:
                    total = q['total']
                    break
            else:
                total = 100
            score_rate = (score / total) * 100
            if score_rate >= 85:
                strong_topics.append(f"{topic} ({score_rate:.1f}%)")
        if strong_topics:
            for topic in strong_topics:
                st.write(f"- {topic}")
        else:
            st.write("æš‚æ— æ˜¾è‘—å¼ºé¡¹")
    with col2:
        st.warning("**å¼±é¡¹**")
        weak_topics = []
        for topic, score in student_result['scores'].items():
            for q in st.session_state.exam_config.get('questions', []):
                if q['title'] == topic:
                    total = q['total']
                    break
            else:
                total = 100
            score_rate = (score / total) * 100
            if score_rate < 70:
                weak_topics.append(f"{topic} ({score_rate:.1f}%)")
        if weak_topics:
            for topic in weak_topics:
                st.write(f"- {topic}")
        else:
            st.write("æš‚æ— æ˜¾è‘—å¼±é¡¹")

    # å¿ƒå¾—ä½“ä¼šæ¦‚è§ˆ
    st.subheader("å¿ƒå¾—ä½“ä¼šæ¦‚è§ˆ")
    if os.path.exists(REFLECTIONS_DIR):
        reflection_files = [f for f in os.listdir(REFLECTIONS_DIR) if f.endswith(".json") and exam_name in f]
        if reflection_files:
            st.write(f"å·²æ”¶é›† {len(reflection_files)} ä»½å¿ƒå¾—ä½“ä¼š")

            # æå–æƒ…ç»ªå’ŒåŠ¨æœºæ•°æ®
            emotion_scores = []
            motivation_scores = []
            for file in reflection_files:
                filepath = os.path.join(REFLECTIONS_DIR, file)
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    analysis = data.get('reflection_analysis', '')

                    emotion_score = extract_emotion_score(analysis)
                    motivation_score = extract_motivation_score(analysis)

                    emotion_scores.append(emotion_score)
                    motivation_scores.append(motivation_score)

            if emotion_scores and motivation_scores:
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å¹³å‡æƒ…ç»ª", f"{np.mean(emotion_scores):.1f}/10")
                with col2:
                    st.metric("å¹³å‡åŠ¨æœº", f"{np.mean(motivation_scores):.1f}/10")
        else:
            st.info("æš‚æ— å¿ƒå¾—ä½“ä¼šæ•°æ®")
    else:
        st.info("å¿ƒå¾—ä½“ä¼šåŠŸèƒ½æœªå¯ç”¨")